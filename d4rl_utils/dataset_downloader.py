#!/usr/bin/env python3
"""
D4RL ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë”
ì§€ì •ëœ ë””ë ‰í† ë¦¬ì— D4RL ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import argparse
from typing import List, Optional
import gym
from d4rl import offline_env
from d4rl.infos import DATASET_URLS, REF_MIN_SCORE, REF_MAX_SCORE


def download_dataset(env_name: str, dataset_type: str = "medium", dataset_dir: str = "./datasets") -> str:
    """
    D4RL ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        env_name: í™˜ê²½ ì´ë¦„ (ì˜ˆ: 'hopper', 'walker2d', 'halfcheetah')
        dataset_type: ë°ì´í„°ì…‹ íƒ€ì… ('random', 'medium', 'expert', 'medium-replay', 'medium-expert')
        dataset_dir: ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        ì €ì¥ëœ ë°ì´í„°ì…‹ì˜ ê²½ë¡œ
    """
    # ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(dataset_dir, exist_ok=True)
    
    # í™˜ê²½ ì´ë¦„ ì •ê·œí™”
    if not env_name.startswith(('hopper', 'walker2d', 'halfcheetah', 'ant')):
        env_name = f"{env_name}-v2"
    
    # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…‹ì¸ì§€ í™•ì¸
    full_env_name = f"{env_name}-{dataset_type}-v2"
    if full_env_name not in DATASET_URLS:
        print(f"âŒ {full_env_name} ë°ì´í„°ì…‹ì€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ì„ í™•ì¸í•˜ë ¤ë©´ --list ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return None
    
    # D4RL í™˜ê²½ ìƒì„± (ìë™ìœ¼ë¡œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ)
    try:
        env = gym.make(full_env_name)
        print(f"âœ… {full_env_name} ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        
        # ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥
        dataset = env.get_dataset()
        print(f"ğŸ“Š ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset['observations'])} ìŠ¤í…")
        print(f"ğŸ“Š ê´€ì°° ì°¨ì›: {dataset['observations'].shape}")
        print(f"ğŸ“Š í–‰ë™ ì°¨ì›: {dataset['actions'].shape}")
        print(f"ğŸ“Š ë³´ìƒ ì°¨ì›: {dataset['rewards'].shape}")
        
        # ë°ì´í„°ì…‹ì„ ì§€ì •ëœ ë””ë ‰í† ë¦¬ì— ì €ì¥
        dataset_path = os.path.join(dataset_dir, f"{full_env_name}.hdf5")
        
        # HDF5 íŒŒì¼ë¡œ ì €ì¥
        import h5py
        with h5py.File(dataset_path, 'w') as f:
            for key, value in dataset.items():
                f.create_dataset(key, data=value)
        
        print(f"ğŸ’¾ ë°ì´í„°ì…‹ì´ {dataset_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        env.close()
        return dataset_path
        
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def download_all_datasets(dataset_dir: str = "./datasets") -> List[str]:
    """
    ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ëª¨ë“  D4RL ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        dataset_dir: ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ì…‹ ê²½ë¡œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
    """
    envs = ['hopper', 'walker2d', 'halfcheetah', 'ant']
    dataset_types = ['random', 'medium', 'expert', 'medium-replay', 'medium-expert']
    
    downloaded_paths = []
    
    for env in envs:
        for dataset_type in dataset_types:
            env_name = f"{env}-{dataset_type}-v2"
            # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…‹ë§Œ ë‹¤ìš´ë¡œë“œ ì‹œë„
            if env_name in DATASET_URLS:
                try:
                    path = download_dataset(env, dataset_type, dataset_dir)
                    if path:
                        downloaded_paths.append(path)
                except Exception as e:
                    print(f"âš ï¸ {env}-{dataset_type} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    continue
            else:
                print(f"â­ï¸ {env}-{dataset_type} ë°ì´í„°ì…‹ì€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    return downloaded_paths


def list_available_datasets():
    """ì‚¬ìš© ê°€ëŠ¥í•œ D4RL ë°ì´í„°ì…‹ ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ D4RL ë°ì´í„°ì…‹:")
    print("=" * 50)
    
    # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…‹ë§Œ í•„í„°ë§
    available_datasets = {}
    
    for env in ['hopper', 'walker2d', 'halfcheetah', 'ant']:
        available_datasets[env] = []
        for dataset_type in ['random', 'medium', 'expert', 'medium-replay', 'medium-expert']:
            env_name = f"{env}-{dataset_type}-v2"
            if env_name in DATASET_URLS:
                available_datasets[env].append((dataset_type, env_name))
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…‹ë§Œ ì¶œë ¥
    for env, datasets in available_datasets.items():
        if datasets:  # ë°ì´í„°ì…‹ì´ ìˆëŠ” í™˜ê²½ë§Œ ì¶œë ¥
            print(f"\nğŸƒ {env.upper()}:")
            for dataset_type, env_name in datasets:
                print(f"  â€¢ {dataset_type}: {env_name}")
                if env_name in REF_MIN_SCORE and env_name in REF_MAX_SCORE:
                    print(f"    ì°¸ì¡° ì ìˆ˜: {REF_MIN_SCORE[env_name]:.1f} ~ {REF_MAX_SCORE[env_name]:.1f}")
                else:
                    print(f"    ì°¸ì¡° ì ìˆ˜: ì •ë³´ ì—†ìŒ")


def main():
    parser = argparse.ArgumentParser(description="D4RL ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë”")
    parser.add_argument("--env", type=str, help="í™˜ê²½ ì´ë¦„ (ì˜ˆ: hopper, walker2d)")
    parser.add_argument("--dataset_type", type=str, default="medium", 
                       help="ë°ì´í„°ì…‹ íƒ€ì… (random, medium, expert, medium-replay, medium-expert)")
    parser.add_argument("--dataset_dir", type=str, default="./datasets",
                       help="ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬")
    parser.add_argument("--all", action="store_true", help="ëª¨ë“  ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ")
    parser.add_argument("--list", action="store_true", help="ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ ì¶œë ¥")
    
    args = parser.parse_args()
    
    if args.list:
        list_available_datasets()
        return
    
    if args.all:
        print("ğŸš€ ëª¨ë“  D4RL ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        downloaded = download_all_datasets(args.dataset_dir)
        print(f"\nâœ… ì´ {len(downloaded)}ê°œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        return
    
    if not args.env:
        print("âŒ í™˜ê²½ ì´ë¦„ì„ ì§€ì •í•´ì£¼ì„¸ìš”. --helpë¡œ ë„ì›€ë§ì„ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    print(f"ğŸš€ {args.env}-{args.dataset_type}-v2 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    download_dataset(args.env, args.dataset_type, args.dataset_dir)


if __name__ == "__main__":
    main()
