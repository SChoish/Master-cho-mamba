#!/usr/bin/env python3
"""
PyTorch Datasetì„ ìƒì†ë°›ëŠ” D4RL Trajectory Dataset
Bambaë¥¼ ìœ„í•œ ê°„ë‹¨í•œ trajectory ì²˜ë¦¬
"""

import os
import numpy as np
import torch
from torch.utils.data import Dataset
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import random
import warnings
warnings.filterwarnings('ignore')


class D4RLTrajectoryDataset(Dataset):
    def __init__(self, env: str, dataset_type: str, dataset_dir: str = "./datasets", 
                 context_length: int = 20):
        """
        D4RL Trajectory Dataset ì´ˆê¸°í™”
        
        Args:
            env: í™˜ê²½ ì´ë¦„ (ì˜ˆ: 'hopper', 'walker2d', 'halfcheetah', 'ant')
            dataset_type: ë°ì´í„°ì…‹ íƒ€ì… ('random', 'medium', 'expert', 'medium-replay', 'medium-expert')
            dataset_dir: HDF5 ë°ì´í„°ì…‹ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
            context_length: trajectoryì˜ ê¸¸ì´
        """
        self.env = env
        self.dataset_type = dataset_type
        self.dataset_dir = Path(dataset_dir)
        self.context_length = context_length
        
        # trajectories ì´ˆê¸°í™”
        self.trajectories = []
        
        # ë°ì´í„°ì…‹ ë¡œë“œ
        self._load_dataset()
        
        # ì •ê·œí™” í†µê³„ ê³„ì‚° ë° ì ìš©
        self._normalize_data()
        
        print(f"âœ… {env}-{dataset_type}-v2: {len(self.trajectories)}ê°œ trajectory ë¡œë“œ ì™„ë£Œ")
    
    def _load_dataset(self):
        """HDF5 ë°ì´í„°ì…‹ì„ trajectory í˜•íƒœë¡œ ë³€í™˜"""
        import h5py
        
        print(f"ğŸš€ {self.env}-{self.dataset_type}-v2 ë°ì´í„°ì…‹ ë¡œë”© ì‹œì‘...")
        
        if not self.dataset_dir.exists():
            raise FileNotFoundError(f"ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.dataset_dir}")
        
        # íŠ¹ì • í™˜ê²½ê³¼ ë°ì´í„°ì…‹ íƒ€ì…ì— í•´ë‹¹í•˜ëŠ” HDF5 íŒŒì¼ ì°¾ê¸°
        target_filename = f"{self.env}-{self.dataset_type}-v2.hdf5"
        hdf5_file = self.dataset_dir / target_filename
        
        if not hdf5_file.exists():
            raise FileNotFoundError(f"ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_filename}")
        
        print(f"ğŸ“ ë¡œë”©í•  íŒŒì¼: {hdf5_file.name}")
        
        # HDF5 íŒŒì¼ ë¡œë“œ
        with h5py.File(hdf5_file, 'r') as f:
            keys = list(f.keys())
            data = {}
            
            for key in keys:
                if key in f and isinstance(f[key], h5py.Dataset):
                    data[key] = f[key][:]
        
        # Trajectory ìƒì„±
        self.trajectories = self._create_trajectories(data)
        
        print(f"ğŸ‰ {self.env}-{self.dataset_type}-v2 ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ")
    
    def _create_trajectories(self, data: Dict) -> List[Dict]:
        """ë°ì´í„°ë¥¼ trajectory í˜•íƒœë¡œ ë³€í™˜"""
        observations = data['observations']
        actions = data['actions']
        rewards = data['rewards']
        next_observations = data['next_observations']
        terminals = data['terminals']
        
        # timeoutsê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
        use_timeouts = 'timeouts' in data
        if use_timeouts:
            timeouts = data['timeouts']
        
        # episode ë‹¨ìœ„ë¡œ ë°ì´í„° ì²˜ë¦¬
        N = len(rewards)
        trajectories = []
        
        # episode ê²½ê³„ ì°¾ê¸°
        if use_timeouts:
            episode_ends = np.where(np.logical_or(terminals, timeouts))[0]
        else:
            episode_ends = np.where(terminals)[0]
        
        # episodeë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
        episode_start = 0
        for episode_end in episode_ends:
            # episode ë°ì´í„° ì¶”ì¶œ
            episode_data = {
                'observations': observations[episode_start:episode_end + 1],
                'next_observations': next_observations[episode_start:episode_end + 1],
                'actions': actions[episode_start:episode_end + 1],
                'rewards': rewards[episode_start:episode_end + 1],
                'terminals': terminals[episode_start:episode_end + 1]
            }
            
            trajectories.append(episode_data)
            episode_start = episode_end + 1
        
        return trajectories
    
    def _normalize_data(self):
        """ë°ì´í„° ì •ê·œí™”"""
        # ëª¨ë“  trajectoryì˜ ìƒíƒœë¥¼ ì—°ê²°í•˜ì—¬ í†µê³„ ê³„ì‚°
        states = []
        for traj in self.trajectories:
            states.append(traj['observations'])
        
        states = np.concatenate(states, axis=0)
        self.state_mean = np.mean(states, axis=0)
        self.state_std = np.std(states, axis=0) + 1e-6
        
        # ìƒíƒœ ì •ê·œí™”
        for traj in self.trajectories:
            traj['observations'] = (traj['observations'] - self.state_mean) / self.state_std
            traj['next_observations'] = (traj['next_observations'] - self.state_mean) / self.state_std
    
    def get_state_stats(self):
        """ìƒíƒœ ì •ê·œí™” í†µê³„ ë°˜í™˜"""
        return self.state_mean, self.state_std
    
    def __len__(self):
        return len(self.trajectories)
    
    def __getitem__(self, idx):
        """ë‹¨ì¼ trajectory ë°˜í™˜"""
        traj = self.trajectories[idx]
        traj_len = traj['observations'].shape[0]
        
        if traj_len >= self.context_length:
            # context_lengthë³´ë‹¤ ê¸´ ê²½ìš° ëœë¤ ìŠ¬ë¼ì´ì‹±
            si = random.randint(0, traj_len - self.context_length)
            
            states = torch.FloatTensor(traj['observations'][si:si + self.context_length])
            next_states = torch.FloatTensor(traj['next_observations'][si:si + self.context_length])
            actions = torch.FloatTensor(traj['actions'][si:si + self.context_length])
            rewards = torch.FloatTensor(traj['rewards'][si:si + self.context_length])
            terminals = torch.FloatTensor(traj['terminals'][si:si + self.context_length])
            
            # ë§ˆì§€ë§‰ ì•¡ì…˜ê³¼ ë³´ìƒë§Œ ì‚¬ìš© (í˜„ì¬ ì‹œì )
            current_action = actions[-1]
            current_reward = rewards[-1].unsqueeze(0)  # (1,)ë¡œ ì°¨ì› ë§ì¶”ê¸°
            current_done = terminals[-1].unsqueeze(0)  # (1,)ë¡œ ì°¨ì› ë§ì¶”ê¸°
            
        else:
            # context_lengthë³´ë‹¤ ì§§ì€ ê²½ìš° íŒ¨ë”©
            padding_len = self.context_length - traj_len
            
            # ìƒíƒœ íŒ¨ë”©
            states = torch.FloatTensor(traj['observations'])
            states = torch.cat([states, torch.zeros(padding_len, states.shape[1])], dim=0)
            
            next_states = torch.FloatTensor(traj['next_observations'])
            next_states = torch.cat([next_states, torch.zeros(padding_len, next_states.shape[1])], dim=0)
            
            # ì•¡ì…˜ íŒ¨ë”©
            actions = torch.FloatTensor(traj['actions'])
            actions = torch.cat([actions, torch.zeros(padding_len, actions.shape[1])], dim=0)
            
            # ë³´ìƒ íŒ¨ë”© (1ì°¨ì›)
            rewards = torch.FloatTensor(traj['rewards'])
            rewards = torch.cat([rewards, torch.zeros(padding_len)], dim=0)
            
            # done í”Œë˜ê·¸ íŒ¨ë”© (1ì°¨ì›)
            terminals = torch.FloatTensor(traj['terminals'])
            terminals = torch.cat([terminals, torch.zeros(padding_len)], dim=0)
            
            # ë§ˆì§€ë§‰ ì•¡ì…˜ê³¼ ë³´ìƒë§Œ ì‚¬ìš© (í˜„ì¬ ì‹œì )
            current_action = actions[traj_len - 1] if traj_len > 0 else torch.zeros(actions.shape[1])
            current_reward = rewards[traj_len - 1].unsqueeze(0) if traj_len > 0 else torch.zeros(1)
            current_done = terminals[traj_len - 1].unsqueeze(0) if traj_len > 0 else torch.zeros(1)
        
        return {
            'states': states,                    # (context_length, state_dim)
            'next_states': next_states,          # (context_length, state_dim)
            'actions': current_action,           # (action_dim,)
            'rewards': current_reward,           # (1,)
            'dones': current_done,               # (1,)
            'traj_len': traj_len                # ì›ë³¸ trajectory ê¸¸ì´
        }


def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    # ë°ì´í„°ì…‹ ì´ˆê¸°í™”
    dataset = D4RLTrajectoryDataset(env="hopper", dataset_type="medium", context_length=20)
    
    # ë°ì´í„°ì…‹ ì •ë³´
    state_mean, state_std = dataset.get_state_stats()
    print(f"\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
    print(f"   Trajectory ìˆ˜: {len(dataset)}")
    print(f"   Context ê¸¸ì´: {dataset.context_length}")
    print(f"   State ì°¨ì›: {state_mean.shape[0]}")
    
    # ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    sample = dataset[0]
    print(f"\nğŸ¯ ìƒ˜í”Œ ë°ì´í„° í˜•íƒœ:")
    for key, value in sample.items():
        if isinstance(value, torch.Tensor):
            print(f"   {key}: {value.shape}")
        else:
            print(f"   {key}: {value}")


if __name__ == "__main__":
    main()
