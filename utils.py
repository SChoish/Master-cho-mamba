#!/usr/bin/env python3
"""
ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
"""

import torch
import numpy as np
import gym
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import json


def set_seed(seed: int = 42):
    """ì‹œë“œ ì„¤ì •"""
    torch.manual_seed(seed)
    np.random.seed(seed)
    import random
    random.seed(seed)


def load_checkpoint(checkpoint_path: str, device: str = "auto"):
    """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
    if device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(device)
    
    checkpoint = torch.load(checkpoint_path, map_location=device)
    return checkpoint, device

def evaluate_bamba_on_environment(model, 
                                device, 
                                context_len, 
                                env_name, 
                                num_eval_ep=10, 
                                max_test_ep_len=1000,
                                state_mean=None, 
                                state_std=None, 
                                render=False):
    """
    Bamba ì—ì´ì „íŠ¸ë¥¼ ì‹¤ì œ í™˜ê²½ì—ì„œ í‰ê°€
    
    Args:
        model: Bamba ì—ì´ì „íŠ¸
        device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
        context_len: context ê¸¸ì´
        env: í™˜ê²½ ì´ë¦„ ë˜ëŠ” í™˜ê²½ ê°ì²´
        num_eval_ep: í‰ê°€í•  ì—í”¼ì†Œë“œ ìˆ˜
        max_test_ep_len: ìµœëŒ€ ì—í”¼ì†Œë“œ ê¸¸ì´
        state_mean: ìƒíƒœ ì •ê·œí™” í‰ê· 
        state_std: ìƒíƒœ ì •ê·œí™” í‘œì¤€í¸ì°¨
        render: ë Œë”ë§ ì—¬ë¶€
        
    Returns:
        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    results = {}
    total_reward = 0
    total_timesteps = 0
    
    # í™˜ê²½ ìƒì„±
    if isinstance(env_name, str):
        try:
            env = gym.make(env_name)
        except Exception as e:
            print(f"âŒ í™˜ê²½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}
    
    state_dim = env.observation_space.shape[0]
    act_dim = env.action_space.shape[0]
    # ì •ê·œí™” í†µê³„ ì„¤ì •
    if state_mean is None:
        state_mean = torch.zeros((state_dim,)).to(device)
    else:
        state_mean = torch.from_numpy(state_mean).to(device)
    
    if state_std is None:
        state_std = torch.ones((state_dim,)).to(device)
    else:
        state_std = torch.from_numpy(state_std).to(device)
    
    print(f"ğŸŒ Bamba í™˜ê²½ í‰ê°€ ì‹œì‘: {env_name}")
    print(f"   State ì°¨ì›: {state_dim}, Action ì°¨ì›: {act_dim}")
    print(f"   Context ê¸¸ì´: {context_len}")
    
    for episode in range(num_eval_ep):
        # í™˜ê²½ ì´ˆê¸°í™”
        running_state = env.reset()
        running_reward = 0
        
        # ìƒíƒœ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        states = torch.zeros((1, max_test_ep_len, state_dim), device=device)
        states[0, 0] = torch.from_numpy(running_state).to(device)
        states[0, 0] = (states[0, 0] - state_mean) / state_std
        
        for t in range(1, max_test_ep_len):
            # context ê¸¸ì´ì— ë”°ë¥¸ ìƒíƒœ ì„ íƒ
            if t < context_len:
                # ì´ˆê¸° ë‹¨ê³„: íŒ¨ë”©ìœ¼ë¡œ context_length ë§ì¶”ê¸°
                current_states = states[:, :t+1]
                # íŒ¨ë”©ìœ¼ë¡œ context_length ë§ì¶”ê¸°
                padding_len = context_len - (t + 1)
                if padding_len > 0:
                    padding = torch.zeros((1, padding_len, state_dim), device=device)
                    current_states = torch.cat([padding, current_states], dim=1)
            else:
                # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
                current_states = states[:, t-context_len+1:t+1]
            
            # Bamba ì—ì´ì „íŠ¸ë¡œ ì•¡ì…˜ ì„ íƒ
            with torch.no_grad():
                # ìƒíƒœë¥¼ Mamba ì¸ì½”ë”ë¡œ ì¸ì½”ë”©
                state_latent = model.encoder.encode_trajectory(current_states)
                # ì•¡ì…˜ ì„ íƒ
                action = model.select_action(state_latent)
                action = action[0].detach()  # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ì‚¬ìš©
            
            # í™˜ê²½ì—ì„œ í–‰ë™ ì‹¤í–‰
            running_state, running_reward, done, _ = env.step(action.cpu().numpy())
            
            # ìƒíƒœ ì €ì¥
            states[0, t] = torch.from_numpy(running_state).to(device)
            states[0, t] = (states[0, t] - state_mean) / state_std
            
            total_reward += running_reward
            
            if render:
                env.render()
            if done:
                break
        
        total_timesteps += t + 1
    
    env.close()
    
    # ê²°ê³¼ ê³„ì‚°
    avg_reward = total_reward / num_eval_ep
    
    # D4RLì—ì„œ ì •í™•í•œ ì„±ëŠ¥ ê¸°ì¤€ ê°€ì ¸ì˜¤ê¸°
    try:
        import d4rl
        from d4rl import infos
        
        # í™˜ê²½ ì´ë¦„ì—ì„œ D4RL í™˜ê²½ëª… ì¶”ì¶œ
        env_name = str(env).split('<')[1].split('>')[0] if '<' in str(env) else str(env)
        
        # D4RL í™˜ê²½ëª… ë§¤í•‘
        if 'hopper' in env_name.lower():
            d4rl_env_name = 'hopper-medium-v2'
        elif 'walker2d' in env_name.lower():
            d4rl_env_name = 'walker2d-medium-v2'
        elif 'halfcheetah' in env_name.lower():
            d4rl_env_name = 'halfcheetah-medium-v2'
        elif 'ant' in env_name.lower():
            d4rl_env_name = 'ant-medium-v2'
        else:
            d4rl_env_name = 'hopper-medium-v2'  # ê¸°ë³¸ê°’
        
        # D4RLì—ì„œ ì •í™•í•œ ì„±ëŠ¥ ê¸°ì¤€ ê°€ì ¸ì˜¤ê¸°
        ref_min_score = infos.REF_MIN_SCORE[d4rl_env_name]
        ref_max_score = infos.REF_MAX_SCORE[d4rl_env_name]
        
        # D4RL ìŠ¤ì½”ì–´ ê³„ì‚° (0-100 ë²”ìœ„)
        d4rl_score = (avg_reward - ref_min_score) / (ref_max_score - ref_min_score) * 100
        d4rl_score = max(0, min(100, d4rl_score))  # 0-100 ë²”ìœ„ë¡œ ì œí•œ
        
    except Exception as e:
        print(f"âš ï¸  D4RL ìŠ¤ì½”ì–´ ê³„ì‚° ì‹¤íŒ¨: {e}")
        d4rl_score = avg_reward
    
    results = {
        'avg_reward': avg_reward,
        'd4rl_score': d4rl_score
    }
    
    print(f"âœ… Bamba í™˜ê²½ í‰ê°€ ì™„ë£Œ")
    print(f"   D4RL ìŠ¤ì½”ì–´: {d4rl_score:.1f}/100")
    
    return results


def save_results(results: Dict, 
                output_dir: str = "results", 
                filename: str = None) -> str:
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    if filename is None:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"results_{timestamp}.json"
    
    filepath = output_path / filename
    
    # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ)
    serializable_results = {}
    for key, value in results.items():
        if isinstance(value, np.ndarray):
            serializable_results[key] = value.tolist()
        elif isinstance(value, np.integer):
            serializable_results[key] = int(value)
        elif isinstance(value, np.floating):
            serializable_results[key] = float(value)
        else:
            serializable_results[key] = value
    
    with open(filepath, 'w') as f:
        json.dump(serializable_results, f, indent=2)
    
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {filepath}")
    return str(filepath)


def load_results(filepath: str) -> Dict:
    """JSON íŒŒì¼ì—ì„œ ê²°ê³¼ ë¡œë“œ"""
    with open(filepath, 'r') as f:
        results = json.load(f)
    return results


def print_model_info(model, device):
    """ëª¨ë¸ ì •ë³´ ì¶œë ¥"""
    print(f"ğŸ”§ ëª¨ë¸ ì •ë³´:")
    print(f"   ë””ë°”ì´ìŠ¤: {device}")
    
    if hasattr(model, 'encoder'):
        total_params = sum(p.numel() for p in model.encoder.parameters())
        trainable_params = sum(p.numel() for p in model.encoder.parameters() if p.requires_grad)
        print(f"   Encoder - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}, í•™ìŠµ ê°€ëŠ¥: {trainable_params:,}")
    
    if hasattr(model, 'q_net'):
        total_params = sum(p.numel() for p in model.q_net.parameters())
        trainable_params = sum(p.numel() for p in model.q_net.parameters() if p.requires_grad)
        print(f"   Q-Net - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}, í•™ìŠµ ê°€ëŠ¥: {trainable_params:,}")


def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    print("ğŸ’¡ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ë ¤ë©´:")
    print("   - set_seed(42)")
    print("   - checkpoint, device = load_checkpoint('path/to/checkpoint.pt')")
    print("   - results = evaluate_on_environment(model, device, context_len, env)")
    print("   - save_results(results, 'results', 'my_results.json')")


if __name__ == "__main__":
    main()